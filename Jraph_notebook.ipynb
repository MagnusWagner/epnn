{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcb48b1",
   "metadata": {},
   "source": [
    "# Testing jraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebddc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_jraph import get_init_crystal_states\n",
    "import jax\n",
    "from preprocessing import get_cutoff_mask, get_init_charges, get_gaussian_distance_encodings, v_center_at_atoms_diagonal, type_to_charges_dict, SYMBOL_MAP\n",
    "from jax import random, numpy as jnp\n",
    "import optax\n",
    "import jraph\n",
    "from typing import Any, Callable, Sequence, Optional, Tuple\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.tree_util as tree\n",
    "import haiku as hk\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80ce5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_implicitly_batched_graphsTuple_with_encoded_distances(descriptors, distances, distances_encoded, init_charges, cutoff_mask, cutoff = 3.0):\n",
    "    batch_size = descriptors.shape[0]\n",
    "    natom = descriptors.shape[1]\n",
    "    # Reshaping the descriptors to go over the whole batch\n",
    "    descriptors = jnp.reshape(descriptors,(batch_size*natom,descriptors.shape[2]))\n",
    "    \n",
    "    # to calculate the number of edges for each individual graph\n",
    "    distances_flattened_batchwise = jnp.reshape(distances,(batch_size,natom*natom))\n",
    "    n_edges = jnp.count_nonzero(jnp.logical_and(distances_flattened_batchwise > 0, distances_flattened_batchwise < cutoff),axis=1)\n",
    "    n_nodes = jnp.repeat(jnp.array([natom]),batch_size)\n",
    "    # Create a flattened index over all previously diagonal elements to be able to delete them from the flattened arrays.\n",
    "    flatten_idx = jnp.nonzero(jnp.logical_and(distances.flatten() > 0, distances.flatten() < cutoff))[0]\n",
    "    idx = jnp.nonzero(jnp.logical_and(distances.flatten() > 0, distances.flatten() < cutoff))[0]\n",
    "    # Make sure that there are only edges between nodes of the same graph\n",
    "    # Batch range to add onto the tiled outer products\n",
    "    batch_range = jnp.reshape(jnp.repeat(jnp.arange(batch_size)*natom,natom*natom),(batch_size,natom,natom))\n",
    "    # outer product over the atoms\n",
    "    outer = jnp.tile(jnp.outer(jnp.ones(natom),jnp.arange(natom)).astype(jnp.int32),batch_size).reshape(batch_size,natom,natom)\n",
    "    # transposed for the other variant\n",
    "    outer_transposed = jnp.transpose(outer, axes=(0,2,1))\n",
    "    senders = jnp.add(outer_transposed,batch_range).flatten()[flatten_idx]\n",
    "    receivers = jnp.add(outer,batch_range).flatten()[flatten_idx]\n",
    "    sender_descriptors = descriptors[senders,:]\n",
    "    receiver_descriptors = descriptors[senders,:]\n",
    "    # Encoded distances are also flattened. Combinations of the same node (diagonal) are deleted\n",
    "    graph_edges = jnp.reshape(distances_encoded,(distances_encoded.shape[0]*distances_encoded.shape[1]*distances_encoded.shape[2],distances_encoded.shape[3]))[flatten_idx,:]\n",
    "    # Same for cutoff_mask\n",
    "    cutoff_mask = cutoff_mask.flatten()[flatten_idx]\n",
    "    # Nodes contain charges\n",
    "    # Edges contain concatenation of descriptors, edge_embeddings and cutoff_mask (which will be removed in the Network)\n",
    "    graph= jraph.GraphsTuple(nodes = init_charges.flatten(),\n",
    "                            # nodes = jnp.concatenate([descriptors,init_charges],axis=-1), Alternative \n",
    "                            senders = senders,\n",
    "                            receivers = receivers,\n",
    "                            edges = jnp.concatenate([receiver_descriptors, sender_descriptors, graph_edges, jnp.expand_dims(cutoff_mask,axis=-1)],axis=-1),\n",
    "                            n_node = n_nodes,\n",
    "                            n_edge = n_edges,\n",
    "                            globals = None)\n",
    "    return graph\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def aggregate_edges_for_nodes_fn(edges: jnp.array,\n",
    "                                receivers: jnp.array,\n",
    "                                cutoff_mask: jnp.array,\n",
    "                                n_nodes: int) -> jnp.array:\n",
    "  edges = jnp.multiply(edges,cutoff_mask)\n",
    "  return jax.ops.segment_sum(edges,receivers,n_nodes)\n",
    "\n",
    "def create_model(features, activation):\n",
    "  if activation == \"swish\":\n",
    "    gep_layer = GraphElectronPassing(\n",
    "      aggregate_edges_for_nodes_fn=aggregate_edges_for_nodes_fn,\n",
    "      MLP = lambda n: MLP_haiku_swish(features=features)(n),\n",
    "    )\n",
    "  else:\n",
    "    gep_layer = GraphElectronPassing(\n",
    "      aggregate_edges_for_nodes_fn=aggregate_edges_for_nodes_fn,\n",
    "      MLP = lambda n: MLP_haiku(features=features)(n),\n",
    "    )\n",
    "  return gep_layer\n",
    "\n",
    "\n",
    "class MLP_haiku(hk.Module):\n",
    "  def __init__(self, features: jnp.ndarray):\n",
    "    super().__init__()\n",
    "    self.features = features\n",
    "\n",
    "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    layers = []\n",
    "    for feat in self.features[:-1]:\n",
    "      layers.append(hk.Linear(feat))\n",
    "      layers.append(jax.nn.relu)\n",
    "    layers.append(hk.Linear(self.features[-1]))\n",
    "    mlp = hk.Sequential(layers)\n",
    "    return mlp(x)\n",
    "\n",
    "class MLP_haiku_swish(hk.Module):\n",
    "  def __init__(self, features: jnp.ndarray):\n",
    "    super().__init__()\n",
    "    self.features = features\n",
    "\n",
    "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    layers = []\n",
    "    for feat in self.features[:-1]:\n",
    "      layers.append(hk.Linear(feat))\n",
    "      layers.append(jax.nn.swish)\n",
    "    layers.append(hk.Linear(self.features[-1]))\n",
    "    mlp = hk.Sequential(layers)\n",
    "    return mlp(x)\n",
    "\n",
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphElectronPassing(aggregate_edges_for_nodes_fn: Callable,\n",
    "                        MLP: Callable,\n",
    "                        h_dim: int = 126) -> Callable:\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_edges_for_nodes_fn: function used to aggregates the sender nodes.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGEP(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    receiver_descriptors = edges[:,:h_dim]\n",
    "    sender_descriptors=edges[:,h_dim:h_dim*2]\n",
    "    graph_edges = edges[:,h_dim*2:-1]\n",
    "    cutoff_mask = jnp.expand_dims(edges[:,-1],axis=-1)\n",
    "    sender_charges = jnp.expand_dims(nodes[senders],axis=-1)\n",
    "    receiver_charges = jnp.expand_dims(nodes[receivers],axis=-1)\n",
    "    # Neural network forward: NN(q_v, q_w, h_v, h_w, e_vw) from the paper\n",
    "    edges = jnp.concatenate([receiver_charges, sender_charges, receiver_descriptors, sender_descriptors, edges],axis=-1)\n",
    "    edges_reversed = jnp.concatenate([sender_charges, receiver_charges, sender_descriptors, receiver_descriptors, edges],axis=-1)\n",
    "    # Subtraction of both outputs to create electron-passing-output for atom v\n",
    "    MLP_outputs = jnp.subtract(MLP(edges),MLP(edges_reversed))\n",
    "    # aggregate_edges_for_nodes_fn is the weighting function with the cutoff_mask\n",
    "    received_attributes = tree.tree_map(\n",
    "      lambda e: aggregate_edges_for_nodes_fn(e, receivers, cutoff_mask, nodes.shape[0]), MLP_outputs)\n",
    "    nodes = received_attributes.flatten()\n",
    "    return graph._replace(nodes=nodes)\n",
    "  return _ApplyGEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14520dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_graph_stats(graph):\n",
    "#     print(\"Nodes-Shape:\",graph[0].shape)\n",
    "#     print(\"Edges-Shape:\",graph[1].shape)\n",
    "#     print(\"Senders-Length:\",graph[2].shape)\n",
    "#     print(\"Globals:\",None if graph[4] is None else graph[4].shape)\n",
    "#     print(\"n_nodes:\",graph[5])\n",
    "#     print(\"n_edges:\",graph[6])\n",
    "\n",
    "# print_graph_stats(train_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7625325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.boxplot(np.array(distances.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb52e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  # except: \n",
    "  #   result_table = result_table.set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with_hyperparameters(E_DIM : int,\n",
    "                                  R_SWITCH : float,\n",
    "                                  R_CUT : float,\n",
    "                                  DISTANCE_ENCODING_TYPE : str,\n",
    "                                  FEATURES : list,\n",
    "                                  NUM_PASSES : int,\n",
    "                                  ACTIVATION : str,\n",
    "                                  N_EPOCHS : int\n",
    "                                  ):\n",
    "    CURRENT_INDEX = (E_DIM, R_SWITCH, R_CUT, DISTANCE_ENCODING_TYPE, str(FEATURES), NUM_PASSES, ACTIVATION, N_EPOCHS)\n",
    "\n",
    "    ######## Results ###############\n",
    "    result_table = pd.read_csv(\"results/result_table.csv\").set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n",
    "    if result_table.index.isin([CURRENT_INDEX]).any():\n",
    "        print(\"Results already in Dataframe.\")\n",
    "    else:\n",
    "        step_list = []\n",
    "        rmse_list_val = []\n",
    "\n",
    "\n",
    "        #################################################\n",
    "        #################################################\n",
    "        print(\"Start training.\")\n",
    "        print(\"Current Parameter-Setting:\",CURRENT_INDEX)\n",
    "        ct = time.time()\n",
    "        best_val_rmse = np.inf\n",
    "        for i in range(N_EPOCHS):\n",
    "            rmse_batch_train_losses = []\n",
    "            for batch_no in range(len(train_batches)):\n",
    "                params, opt_state = update(train_batches[batch_no],true_labels[batch_no], params, opt_state)\n",
    "            for batch_no in range(len(train_batches)):\n",
    "                rmse_batch_train_losses.append(rmse_loss(params, train_batches[batch_no],true_labels[batch_no]))\n",
    "            val_rmse = float(rmse_loss(params, val_batch, true_labels_val))\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "            if (i % 10)==0:\n",
    "                step_list.append(i)\n",
    "                rmse_list_val.append(val_rmse)\n",
    "                print(\"Epoch:\",i,\"-  Train-RMSE:\", round(float(sum(rmse_batch_train_losses)/len(rmse_batch_train_losses)),5),\" -  Val-RMSE:\", round(val_rmse,5))\n",
    "        time_taken = round((time.time()-ct)/60,2)\n",
    "        test_rmse = rmse_loss(params, test_batch, true_labels_test)\n",
    "        test_mae = mae_loss(params, test_batch, true_labels_test)\n",
    "\n",
    "        if result_table.index.isin([CURRENT_INDEX]).any():\n",
    "            result_table.loc[CURRENT_INDEX] = time_taken, test_rmse, test_mae, list(step_list), list(rmse_list_val)\n",
    "        else:\n",
    "            result_table = result_table.reset_index().append(dict(zip([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\",\"time_needed\",\"test_rmse\",\"test_mae\",\"steps\",\"val_rmses\", \"best_val_rmse\"],[E_DIM, R_SWITCH, R_CUT, DISTANCE_ENCODING_TYPE, str(FEATURES), NUM_PASSES, ACTIVATION, N_EPOCHS, time_taken, test_rmse, test_mae, list(step_list), list(rmse_list_val), best_val_rmse])), ignore_index = True).set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n",
    "\n",
    "        print(\"Best-Val-RMSE:\",best_val_rmse)\n",
    "        result_table.to_csv(\"results/result_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fae8c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2374e4f68a514fa885456b6c91851dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training.\n",
      "Current Parameter-Setting: (36, 0.5, 10.0, 'none', '[64, 32, 16, 8, 1]', 3, 'relu', 800)\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Epoch: 0 -  Train-RMSE: 1.08411  -  Val-RMSE: 1.08532\n",
      "Epoch: 10 -  Train-RMSE: 0.21393  -  Val-RMSE: 0.21555\n",
      "Epoch: 20 -  Train-RMSE: 0.08769  -  Val-RMSE: 0.09333\n",
      "Epoch: 30 -  Train-RMSE: 0.09469  -  Val-RMSE: 0.09825\n",
      "Epoch: 40 -  Train-RMSE: 0.05957  -  Val-RMSE: 0.06492\n",
      "Epoch: 50 -  Train-RMSE: 0.10059  -  Val-RMSE: 0.10397\n",
      "Epoch: 60 -  Train-RMSE: 0.078  -  Val-RMSE: 0.08305\n",
      "Epoch: 70 -  Train-RMSE: 0.07425  -  Val-RMSE: 0.0793\n",
      "Epoch: 80 -  Train-RMSE: 0.05582  -  Val-RMSE: 0.06118\n",
      "Epoch: 90 -  Train-RMSE: 0.05485  -  Val-RMSE: 0.05976\n",
      "Epoch: 100 -  Train-RMSE: 0.04583  -  Val-RMSE: 0.05028\n",
      "Epoch: 110 -  Train-RMSE: 0.03958  -  Val-RMSE: 0.04467\n",
      "Epoch: 120 -  Train-RMSE: 0.04168  -  Val-RMSE: 0.04673\n",
      "Epoch: 130 -  Train-RMSE: 0.03719  -  Val-RMSE: 0.04265\n",
      "Epoch: 140 -  Train-RMSE: 0.0366  -  Val-RMSE: 0.04169\n",
      "Epoch: 150 -  Train-RMSE: 0.03992  -  Val-RMSE: 0.04359\n",
      "Epoch: 160 -  Train-RMSE: 0.0325  -  Val-RMSE: 0.0379\n",
      "Epoch: 170 -  Train-RMSE: 0.03312  -  Val-RMSE: 0.03872\n",
      "Epoch: 180 -  Train-RMSE: 0.03333  -  Val-RMSE: 0.03811\n",
      "Epoch: 190 -  Train-RMSE: 0.03502  -  Val-RMSE: 0.04018\n",
      "Epoch: 200 -  Train-RMSE: 0.03205  -  Val-RMSE: 0.03707\n",
      "Epoch: 210 -  Train-RMSE: 0.02958  -  Val-RMSE: 0.03503\n",
      "Epoch: 220 -  Train-RMSE: 0.03205  -  Val-RMSE: 0.03719\n",
      "Epoch: 230 -  Train-RMSE: 0.02898  -  Val-RMSE: 0.03465\n",
      "Epoch: 240 -  Train-RMSE: 0.03046  -  Val-RMSE: 0.03605\n",
      "Epoch: 250 -  Train-RMSE: 0.02864  -  Val-RMSE: 0.03433\n",
      "Epoch: 260 -  Train-RMSE: 0.03078  -  Val-RMSE: 0.03625\n",
      "Epoch: 270 -  Train-RMSE: 0.03087  -  Val-RMSE: 0.03598\n",
      "Epoch: 280 -  Train-RMSE: 0.02754  -  Val-RMSE: 0.0338\n",
      "Epoch: 290 -  Train-RMSE: 0.03191  -  Val-RMSE: 0.03853\n",
      "Epoch: 300 -  Train-RMSE: 0.03128  -  Val-RMSE: 0.03727\n",
      "Epoch: 310 -  Train-RMSE: 0.03373  -  Val-RMSE: 0.0392\n",
      "Epoch: 320 -  Train-RMSE: 0.03476  -  Val-RMSE: 0.04066\n",
      "Epoch: 330 -  Train-RMSE: 0.02682  -  Val-RMSE: 0.03412\n",
      "Epoch: 340 -  Train-RMSE: 0.03427  -  Val-RMSE: 0.04064\n",
      "Epoch: 350 -  Train-RMSE: 0.03111  -  Val-RMSE: 0.03741\n",
      "Epoch: 360 -  Train-RMSE: 0.0268  -  Val-RMSE: 0.03426\n",
      "Epoch: 370 -  Train-RMSE: 0.02852  -  Val-RMSE: 0.035\n",
      "Epoch: 380 -  Train-RMSE: 0.02861  -  Val-RMSE: 0.03579\n",
      "Epoch: 390 -  Train-RMSE: 0.05262  -  Val-RMSE: 0.05604\n",
      "Epoch: 400 -  Train-RMSE: 0.03247  -  Val-RMSE: 0.03936\n",
      "Epoch: 410 -  Train-RMSE: 0.02934  -  Val-RMSE: 0.03769\n",
      "Epoch: 420 -  Train-RMSE: 0.02837  -  Val-RMSE: 0.03507\n",
      "Epoch: 430 -  Train-RMSE: 0.0285  -  Val-RMSE: 0.03557\n",
      "Epoch: 440 -  Train-RMSE: 0.02783  -  Val-RMSE: 0.03592\n",
      "Epoch: 450 -  Train-RMSE: 0.05115  -  Val-RMSE: 0.05369\n",
      "Epoch: 460 -  Train-RMSE: 0.14629  -  Val-RMSE: 0.1459\n",
      "Epoch: 470 -  Train-RMSE: 0.07715  -  Val-RMSE: 0.07959\n",
      "Epoch: 480 -  Train-RMSE: 0.06459  -  Val-RMSE: 0.06718\n",
      "Epoch: 490 -  Train-RMSE: 0.04921  -  Val-RMSE: 0.05233\n",
      "Epoch: 500 -  Train-RMSE: 0.04809  -  Val-RMSE: 0.05112\n",
      "Epoch: 510 -  Train-RMSE: 0.04097  -  Val-RMSE: 0.04458\n",
      "Epoch: 520 -  Train-RMSE: 0.03979  -  Val-RMSE: 0.04365\n",
      "Epoch: 530 -  Train-RMSE: 0.05346  -  Val-RMSE: 0.05611\n",
      "Epoch: 540 -  Train-RMSE: 0.04401  -  Val-RMSE: 0.04707\n",
      "Epoch: 550 -  Train-RMSE: 0.03861  -  Val-RMSE: 0.04179\n",
      "Epoch: 560 -  Train-RMSE: 0.08023  -  Val-RMSE: 0.08213\n",
      "Epoch: 570 -  Train-RMSE: 0.03623  -  Val-RMSE: 0.04078\n",
      "Epoch: 580 -  Train-RMSE: 0.05487  -  Val-RMSE: 0.05856\n",
      "Epoch: 590 -  Train-RMSE: 0.04565  -  Val-RMSE: 0.04936\n",
      "Epoch: 600 -  Train-RMSE: 0.03986  -  Val-RMSE: 0.04412\n",
      "Epoch: 610 -  Train-RMSE: 0.03574  -  Val-RMSE: 0.04029\n",
      "Epoch: 620 -  Train-RMSE: 0.03245  -  Val-RMSE: 0.03753\n",
      "Epoch: 630 -  Train-RMSE: 0.03563  -  Val-RMSE: 0.0404\n",
      "Epoch: 640 -  Train-RMSE: 0.03403  -  Val-RMSE: 0.03955\n",
      "Epoch: 650 -  Train-RMSE: 0.05997  -  Val-RMSE: 0.06185\n",
      "Epoch: 660 -  Train-RMSE: 0.04714  -  Val-RMSE: 0.05487\n",
      "Epoch: 670 -  Train-RMSE: 0.04285  -  Val-RMSE: 0.04602\n",
      "Epoch: 680 -  Train-RMSE: 0.03487  -  Val-RMSE: 0.03852\n",
      "Epoch: 690 -  Train-RMSE: 0.04308  -  Val-RMSE: 0.04476\n",
      "Epoch: 700 -  Train-RMSE: 0.03342  -  Val-RMSE: 0.03689\n",
      "Epoch: 710 -  Train-RMSE: 0.03485  -  Val-RMSE: 0.0374\n",
      "Epoch: 720 -  Train-RMSE: 0.03557  -  Val-RMSE: 0.03854\n",
      "Epoch: 730 -  Train-RMSE: 0.04409  -  Val-RMSE: 0.04607\n",
      "Epoch: 740 -  Train-RMSE: 0.03264  -  Val-RMSE: 0.03603\n",
      "Epoch: 750 -  Train-RMSE: 0.03452  -  Val-RMSE: 0.03731\n",
      "Epoch: 760 -  Train-RMSE: 0.03403  -  Val-RMSE: 0.0366\n",
      "Epoch: 770 -  Train-RMSE: 0.03598  -  Val-RMSE: 0.03829\n",
      "Epoch: 780 -  Train-RMSE: 0.03168  -  Val-RMSE: 0.03513\n",
      "Epoch: 790 -  Train-RMSE: 0.04488  -  Val-RMSE: 0.0485\n",
      "3\n",
      "Best-Val-RMSE: 0.0322735458612442\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gridsearch_dict = {\n",
    "    \"e_dim\":[6,12,24,48,96],\n",
    "    \"r_switch\":[0.1, 0.5, 1.0, 2.0],\n",
    "    \"r_cut\":[1.0,2.0,5.0,10.0],\n",
    "    \"r_switch_cut\" : [(0.1,1.0),(0.5,2.0),(1.0,5.0),(2.0,10.0),(0.5,10.0),(0.1,5.0),(1.0,2.0),(0.1,15.0),(0.1,20.0),(0.1,10.0)],\n",
    "    \"distance_encoding_type\": [\"none\"],\n",
    "    \"features\":[[32,32,1],[32,32,32,1],[64,32,1],[16,16,16,16,16,1],[64,32,16,8,4,1],[64,64,1],[64,32,32,1]],\n",
    "    # \"num_passes\":[1,2,3,4,5],\n",
    "    \"num_passes\":[3],\n",
    "    \"activation\":[\"relu\",\"switch\"],\n",
    "}\n",
    "############### Example loops ###################\n",
    "# for E_DIM in gridsearch_dict[\"e_dim\"]:\n",
    "# # for R_SWITCH in gridsearch_dict[\"r_switch\"]:\n",
    "# for R_SWITCH, R_CUT in gridsearch_dict[\"r_switch_cut\"]:\n",
    "# for DISTANCE_ENCODING_TYPE in gridsearch_dict[\"distance_encoding_type\"]:\n",
    "# for FEATURES in gridsearch_dict[\"features\"]:\n",
    "# for NUM_PASSES in gridsearch_dict[\"num_passes\"]:\n",
    "# for ACTIVATION in gridsearch_dict[\"activation\"]:\n",
    "\n",
    "\n",
    "#######################################\n",
    "###### HYPERPARAMETERS ################\n",
    "E_DIM = 36\n",
    "R_SWITCH = 0.5\n",
    "R_CUT = 10.0\n",
    "DISTANCE_ENCODING_TYPE = \"none\"\n",
    "FEATURES = [64,32,16,8,1]\n",
    "# FEATURES = [128,64,32,1]\n",
    "NUM_PASSES = 3\n",
    "ACTIVATION = \"relu\"\n",
    "N_EPOCHS = 800\n",
    "\n",
    "\n",
    "#######################################\n",
    "## loading input values from file #####\n",
    "\n",
    "key, subkey = random.split(random.PRNGKey(0))\n",
    "h_dim = 126\n",
    "path = \"data/SrTiO3_500.db\"\n",
    "descriptors, distances, distances_encoded, init_charges, gt_charges, cutoff_mask, types = get_init_crystal_states(path, edge_encoding_dim = E_DIM, SAMPLE_SIZE = None, r_switch = R_SWITCH, r_cut = R_CUT, distance_encoding_type = DISTANCE_ENCODING_TYPE) # Change sample size to None if all samples should be read.\n",
    "\n",
    "#######################################\n",
    "### Creating batches for training #####\n",
    "\n",
    "total_size = descriptors.shape[0]\n",
    "train_batch_size = 50\n",
    "test_size = 50\n",
    "val_size = 50\n",
    "train_size = total_size - test_size - val_size\n",
    "key = random.PRNGKey(0)\n",
    "permuted_idx = random.permutation(key, jnp.arange(500))\n",
    "test_idx = permuted_idx[-test_size:]\n",
    "val_idx = permuted_idx[-2*test_size:-test_size]\n",
    "train_idxs = jnp.array(jnp.split(permuted_idx[:-2*test_size],int(jnp.ceil(train_size/train_batch_size))))\n",
    "train_batches = [create_implicitly_batched_graphsTuple_with_encoded_distances(descriptors[train_idx],distances[train_idx], distances_encoded[train_idx],init_charges[train_idx],cutoff_mask[train_idx]) for train_idx in train_idxs]\n",
    "val_batch = create_implicitly_batched_graphsTuple_with_encoded_distances(descriptors[val_idx],distances[val_idx], distances_encoded[val_idx],init_charges[val_idx],cutoff_mask[val_idx])\n",
    "test_batch = create_implicitly_batched_graphsTuple_with_encoded_distances(descriptors[test_idx],distances[test_idx], distances_encoded[test_idx],init_charges[test_idx],cutoff_mask[test_idx])\n",
    "\n",
    "for DISTANCE_ENCODING_TYPE in gridsearch_dict[\"distance_encoding_type\"]:\n",
    "    gep_layer = create_model(FEATURES,ACTIVATION)\n",
    "    ################################\n",
    "    model = hk.without_apply_rng(hk.transform(gep_layer))\n",
    "    params = model.init(jax.random.PRNGKey(42), train_batches[0])\n",
    "    true_labels = [gt_charges[train_idx].flatten() for train_idx in train_idxs]\n",
    "    true_labels_val = gt_charges[val_idx].flatten()\n",
    "    true_labels_test = gt_charges[test_idx].flatten()\n",
    "    opt_init, opt_update = optax.adam(1e-2)\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    # Create loss functions with correct NUM_PASSES and model\n",
    "    @jax.jit\n",
    "    def rmse_loss(params: hk.Params, graph: jraph.GraphsTuple,  ground_truth: jnp.array) -> jnp.ndarray:\n",
    "        # hk.fori_loop(0,3, model.apply, graph, params=params)\n",
    "        output = model.apply(params, graph)\n",
    "        print(NUM_PASSES)\n",
    "        for i in range(NUM_PASSES-1):\n",
    "          output = model.apply(params, output)\n",
    "        return jnp.sqrt(jnp.sum(jnp.square(output[0]-ground_truth)/len(ground_truth)))\n",
    "\n",
    "    @jax.jit\n",
    "    def mae_loss(params: hk.Params, graph: jraph.GraphsTuple,  ground_truth: jnp.array) -> jnp.ndarray:\n",
    "        # hk.fori_loop(0,3, model.apply, graph, params=params)\n",
    "        output = model.apply(params, graph)\n",
    "        for i in range(NUM_PASSES-1):\n",
    "          output = model.apply(params, output)\n",
    "        return jnp.sum(jnp.abs(output[0]-ground_truth)/len(ground_truth))\n",
    "\n",
    "    @jax.jit\n",
    "    def update(train_batch: jraph.GraphsTuple, true_labels:jnp.array, params: hk.Params, opt_state) -> Tuple[hk.Params, Any]:\n",
    "        \"\"\"Returns updated params and state.\"\"\"\n",
    "        g = jax.grad(rmse_loss)(params, train_batch, true_labels)\n",
    "        updates, opt_state = opt_update(g, opt_state)\n",
    "        return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "\n",
    "\n",
    "    CURRENT_INDEX = (E_DIM, R_SWITCH, R_CUT, DISTANCE_ENCODING_TYPE, str(FEATURES), NUM_PASSES, ACTIVATION, N_EPOCHS)\n",
    "    result_table = pd.read_csv(\"results/result_table.csv\").set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n",
    "    if result_table.index.isin([CURRENT_INDEX]).any():\n",
    "        print(\"Results already in Dataframe.\")\n",
    "    else:\n",
    "        ######## Results ###############\n",
    "        result_table = pd.read_csv(\"results/result_table.csv\").set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n",
    "        if result_table.index.isin([CURRENT_INDEX]).any():\n",
    "            print(\"Results already in Dataframe.\")\n",
    "        else:\n",
    "            step_list = []\n",
    "            rmse_list_val = []\n",
    "            #################################################\n",
    "            #################################################\n",
    "            print(\"Start training.\")\n",
    "            print(\"Current Parameter-Setting:\",CURRENT_INDEX)\n",
    "            ct = time.time()\n",
    "            best_val_rmse = np.inf\n",
    "            best_model = None\n",
    "            for i in range(N_EPOCHS):\n",
    "                rmse_batch_train_losses = []\n",
    "                for batch_no in range(len(train_batches)):\n",
    "                    params, opt_state = update(train_batches[batch_no],true_labels[batch_no], params, opt_state)\n",
    "                for batch_no in range(len(train_batches)):\n",
    "                    rmse_batch_train_losses.append(rmse_loss(params, train_batches[batch_no],true_labels[batch_no]))\n",
    "                val_rmse = float(rmse_loss(params, val_batch, true_labels_val))\n",
    "                if val_rmse < best_val_rmse:\n",
    "                    best_val_rmse = val_rmse\n",
    "                    best_model = model\n",
    "                if (i % 10)==0:\n",
    "                    step_list.append(i)\n",
    "                    rmse_list_val.append(val_rmse)\n",
    "                    print(\"Epoch:\",i,\"-  Train-RMSE:\", round(float(sum(rmse_batch_train_losses)/len(rmse_batch_train_losses)),5),\" -  Val-RMSE:\", round(val_rmse,5))\n",
    "            time_taken = round((time.time()-ct)/60,2)\n",
    "            test_rmse = rmse_loss(params, test_batch, true_labels_test)\n",
    "            test_mae = mae_loss(params, test_batch, true_labels_test)\n",
    "\n",
    "            if result_table.index.isin([CURRENT_INDEX]).any():\n",
    "                result_table.loc[CURRENT_INDEX] = time_taken, test_rmse, test_mae, list(step_list), list(rmse_list_val)\n",
    "            else:\n",
    "                result_table = result_table.reset_index().append(dict(zip([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\",\"time_needed\",\"test_rmse\",\"test_mae\",\"steps\",\"val_rmses\", \"best_val_rmse\"],[E_DIM, R_SWITCH, R_CUT, DISTANCE_ENCODING_TYPE, str(FEATURES), NUM_PASSES, ACTIVATION, N_EPOCHS, time_taken, test_rmse, test_mae, list(step_list), list(rmse_list_val), best_val_rmse])), ignore_index = True).set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n",
    "\n",
    "            print(\"Best-Val-RMSE:\",best_val_rmse)\n",
    "            result_table.to_csv(\"results/result_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a305aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024786495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'actual charges')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_mae = mae_loss(params, test_batch, true_labels_test)\n",
    "print(test_mae)\n",
    "output = best_model.apply(params, test_batch)\n",
    "for i in range(NUM_PASSES-1):\n",
    "    output = model.apply(params, output)\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(output[0],true_labels_test,\".\",ms=2)\n",
    "plt.plot([-1.8,2.2],[-1.8,2.2],color=\"red\", ms=0.5)\n",
    "plt.xlabel(\"predicted charges\")\n",
    "plt.ylabel(\"actual charges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028502e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40f8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 0.5, 10.0, 'none', '[64, 32, 16, 8, 1]', 3, 'relu', 800)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table = pd.read_csv(\"results/result_table.csv\").set_index([\"e_dim\",\"r_switch\",\"r_cut\",\"distance_encoding_type\",\"features\",\"num_passes\",\"activation_fn\",\"n_epochs\"])\n",
    "CURRENT_INDEX = (E_DIM, R_SWITCH, R_CUT, \"ROOT\", str(FEATURES), NUM_PASSES, ACTIVATION, N_EPOCHS)\n",
    "# print(CURRENT_INDEX)\n",
    "# result_table.loc[CURRENT_INDEX][\"best_val_rmse\"]\n",
    "result_table.sort_values(by=\"best_val_rmse\").index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e2838e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graphsTuple_with_encoded_distances(descriptors, distances, distances_encoded, init_charges, cutoff_mask, cutoff = R_CUT):\n",
    "#     natom = descriptors.shape[0]\n",
    "#     # Create a flattened index over all previously diagonal elements to be able to delete them from the flattened arrays. \n",
    "#     flatten_idx = jnp.nonzero(jnp.logical_and(distances > 0, distances < cutoff).flatten())[0]\n",
    "#     senders = jnp.outer(jnp.ones(natom),jnp.arange(natom)).T.flatten()[flatten_idx].astype(jnp.int32)\n",
    "#     receivers = jnp.outer(jnp.ones(natom),jnp.arange(natom)).flatten()[flatten_idx].astype(jnp.int32)\n",
    "#     sender_descriptors = descriptors[senders,:]\n",
    "#     # print(senders,receivers)\n",
    "#     receiver_descriptors = descriptors[senders,:]\n",
    "#     n_nodes = jnp.array([natom])\n",
    "#     n_edges = jnp.array([natom*natom-natom])\n",
    "#     # Encoded distances are also flattened. Combinations of the same node (diagonal) are deleted\n",
    "#     graph_edges = jnp.reshape(distances_encoded,(distances_encoded.shape[0]*distances_encoded.shape[1],48))[flatten_idx,:]\n",
    "#     # Same for cutoff_mask\n",
    "#     cutoff_mask = cutoff_mask.flatten()[flatten_idx]\n",
    "#     # Nodes contain charges\n",
    "#     # Edges contain concatenation of descriptors, edge_embeddings and cutoff_mask (which will be removed in the Network)\n",
    "#     graph= jraph.GraphsTuple(nodes = init_charges,\n",
    "#                             # nodes = jnp.concatenate([descriptors,init_charges],axis=-1), Alternative \n",
    "#                             senders = senders,\n",
    "#                             receivers = receivers,\n",
    "#                             edges = jnp.concatenate([receiver_descriptors, sender_descriptors, graph_edges, jnp.expand_dims(cutoff_mask,axis=-1)],axis=-1),\n",
    "#                             n_node = n_nodes,\n",
    "#                             n_edge = n_edges,\n",
    "#                             globals = None)\n",
    "#     return graph\n",
    "\n",
    "# graph = create_graphsTuple_with_encoded_distances(descriptors[0],distances[0], distances_encoded[0],init_charges[0],cutoff_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f102626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# natom = 4\n",
    "# batch_size = 2\n",
    "\n",
    "# batch_range = jnp.reshape(jnp.repeat(jnp.arange(batch_size)*natom,natom*natom),(batch_size,natom,natom))\n",
    "# outer = jnp.tile(jnp.outer(jnp.ones(natom),jnp.arange(natom)).astype(jnp.int32),batch_size).reshape(batch_size,natom,natom)\n",
    "# outer_transposed = jnp.transpose(outer, axes=(0,2,1))\n",
    "# senders = jnp.add(outer_transposed,batch_range).flatten()\n",
    "# receivers = jnp.add(outer,batch_range).flatten()\n",
    "\n",
    "# senders, receivers"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c05abb91804ff133a19a050f1bf5090a0f034e3cc9a55e2ab0df108b485f2fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
